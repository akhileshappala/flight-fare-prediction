{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are all the modules required to prepare our machine learning algorithm.  We are using here Random Forest Regression algorithm. \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "\n",
    "# This line is to show plots inside the jupyter notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\python\\lib\\site-packages\\sklearn\\grid_search.py:42: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics   #Additional scklearn functions\n",
    "from sklearn.grid_search import GridSearchCV   #Perforing grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ITIN_ID</th>\n",
       "      <th>COUPONS</th>\n",
       "      <th>YEAR</th>\n",
       "      <th>QUARTER</th>\n",
       "      <th>ORIGIN</th>\n",
       "      <th>ORIGIN_AIRPORT_ID</th>\n",
       "      <th>ORIGIN_AIRPORT_SEQ_ID</th>\n",
       "      <th>ORIGIN_CITY_MARKET_ID</th>\n",
       "      <th>ORIGIN_COUNTRY</th>\n",
       "      <th>ORIGIN_STATE_FIPS</th>\n",
       "      <th>...</th>\n",
       "      <th>ITIN_YIELD</th>\n",
       "      <th>REPORTING_CARRIER</th>\n",
       "      <th>PASSENGERS</th>\n",
       "      <th>ITIN_FARE</th>\n",
       "      <th>BULK_FARE</th>\n",
       "      <th>DISTANCE</th>\n",
       "      <th>DISTANCE_GROUP</th>\n",
       "      <th>MILES_FLOWN</th>\n",
       "      <th>ITIN_GEO_TYPE</th>\n",
       "      <th>Unnamed: 25</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>201719</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>ABE</td>\n",
       "      <td>10135</td>\n",
       "      <td>1013503</td>\n",
       "      <td>30135</td>\n",
       "      <td>US</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5482</td>\n",
       "      <td>9E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1</td>\n",
       "      <td>425.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017110</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>ABE</td>\n",
       "      <td>10135</td>\n",
       "      <td>1013503</td>\n",
       "      <td>30135</td>\n",
       "      <td>US</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.8447</td>\n",
       "      <td>9E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>359.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1</td>\n",
       "      <td>425.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017111</td>\n",
       "      <td>1</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>ABE</td>\n",
       "      <td>10135</td>\n",
       "      <td>1013503</td>\n",
       "      <td>30135</td>\n",
       "      <td>US</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.9153</td>\n",
       "      <td>9E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>389.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>425.0</td>\n",
       "      <td>1</td>\n",
       "      <td>425.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017112</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>ABE</td>\n",
       "      <td>10135</td>\n",
       "      <td>1013503</td>\n",
       "      <td>30135</td>\n",
       "      <td>US</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>9E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>2</td>\n",
       "      <td>850.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017113</td>\n",
       "      <td>2</td>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>ABE</td>\n",
       "      <td>10135</td>\n",
       "      <td>1013503</td>\n",
       "      <td>30135</td>\n",
       "      <td>US</td>\n",
       "      <td>42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2306</td>\n",
       "      <td>9E</td>\n",
       "      <td>1.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>850.0</td>\n",
       "      <td>2</td>\n",
       "      <td>850.0</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ITIN_ID  COUPONS  YEAR  QUARTER ORIGIN  ORIGIN_AIRPORT_ID  \\\n",
       "0   201719        1  2017        1    ABE              10135   \n",
       "1  2017110        1  2017        1    ABE              10135   \n",
       "2  2017111        1  2017        1    ABE              10135   \n",
       "3  2017112        2  2017        1    ABE              10135   \n",
       "4  2017113        2  2017        1    ABE              10135   \n",
       "\n",
       "   ORIGIN_AIRPORT_SEQ_ID  ORIGIN_CITY_MARKET_ID ORIGIN_COUNTRY  \\\n",
       "0                1013503                  30135             US   \n",
       "1                1013503                  30135             US   \n",
       "2                1013503                  30135             US   \n",
       "3                1013503                  30135             US   \n",
       "4                1013503                  30135             US   \n",
       "\n",
       "   ORIGIN_STATE_FIPS     ...      ITIN_YIELD REPORTING_CARRIER  PASSENGERS  \\\n",
       "0                 42     ...          0.5482                9E         1.0   \n",
       "1                 42     ...          0.8447                9E         1.0   \n",
       "2                 42     ...          0.9153                9E         1.0   \n",
       "3                 42     ...          0.2306                9E         1.0   \n",
       "4                 42     ...          0.2306                9E         1.0   \n",
       "\n",
       "   ITIN_FARE  BULK_FARE  DISTANCE  DISTANCE_GROUP MILES_FLOWN  ITIN_GEO_TYPE  \\\n",
       "0      233.0        0.0     425.0               1       425.0              2   \n",
       "1      359.0        0.0     425.0               1       425.0              2   \n",
       "2      389.0        0.0     425.0               1       425.0              2   \n",
       "3      196.0        0.0     850.0               2       850.0              2   \n",
       "4      196.0        0.0     850.0               2       850.0              2   \n",
       "\n",
       "   Unnamed: 25  \n",
       "0          NaN  \n",
       "1          NaN  \n",
       "2          NaN  \n",
       "3          NaN  \n",
       "4          NaN  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import savReaderWriter as spss\n",
    "\n",
    "# we are loading our data in a \"data\" variable.\n",
    "data = pd.read_csv(\"data/data_aa.csv\")\n",
    "# data = spss.SavReader('data/data.csv', returnHeader = True) # This is fast\n",
    "\n",
    "# from all the data we are just selecting \"ITIN_YIELD\" and \"DISTANCE\" column to use and saving these columns to \"source_data\"\n",
    "source_data = data[['ITIN_YIELD', 'DISTANCE']]\n",
    "\n",
    "# from those two column we are trying to predict \"ITIN_FARE\" column. So we are also saving the column in \"predicted_column\" variable\n",
    "predicted_column = data['ITIN_FARE']\n",
    "\n",
    "# with this line we are just showing first 5 line of our all data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, presort='auto', random_state=10,\n",
       "             subsample=1.0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inside the \"train_test_split()\" we are providing our data. And populating our X_train, Y_train, X_test and Y_test variables\n",
    "# X_train variable contains the data of  our training \"source_data\" \n",
    "# X_test variable contains the data of  our testing \"sourse_data\"\n",
    "# Y_train variable contains the data of  our training \"predicted_column\"\n",
    "# Y_test variable contains the data of  our testing \"predicted_column\"\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(source_data, predicted_column, random_state=42)\n",
    "\n",
    "\n",
    "# we are loading our algorithm in \"forest\" variable\n",
    "gbr = GradientBoostingRegressor(random_state=10)\n",
    "\n",
    "# we are telling our algorithm to train from our training dataset\n",
    "gbr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: [202.86973657]\n"
     ]
    }
   ],
   "source": [
    "# Now we are trying to predict our estimated fare from by giving our algorithm some value. And we can see that, its trying to predict.\n",
    "\n",
    "X_new = np.array([[0.2306, 850.0]])\n",
    "prediction = gbr.predict(X_new)\n",
    "print(\"Prediction: {}\".format(prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set predictions:\n",
      " [581.54740008 329.00988019  29.62785941 ... 280.49688295 464.92364484\n",
      " 286.26910738]\n"
     ]
    }
   ],
   "source": [
    "# Now we are giving our algorithm our test data set. So that, it can try to predict the values of test data also.\n",
    "\n",
    "y_pred = gbr.predict(X_test)\n",
    "print(\"Test set predictions:\\n {}\".format(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set: 0.987\n",
      "Accuracy on test set: 0.983\n"
     ]
    }
   ],
   "source": [
    "# Here are we are trying to watch our prediction score. How much it can learn from our training and testing data.\n",
    "\n",
    "print(\"Accuracy on training set: {:.3f}\".format(gbr.score(X_train, y_train)))\n",
    "print(\"Accuracy on test set: {:.3f}\".format(gbr.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
